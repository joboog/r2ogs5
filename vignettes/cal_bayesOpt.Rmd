---
title: "Bayesian Optimization to calibrate OGS5 models"
output: 
  rmarkdown::html_vignette:
    fig_caption: yes
descritption: >
    This is a tutorial on calibration of ogs5 process models with the bayesian         optimization algorithm provided in the *r2ogs5 package. For the basic functions     of r2ogs5, please refer to `vignette("r2ogs5")`. 
vignette: >
  %\VignetteIndexEntry{Bayesian Optimization to calibrate OGS5 models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: vignettes_lib.bib
header-includes:
  - \counterwithin{figure}{section}
  - \counterwithin{table}{section}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(tibble.print_min = 4L, tibble.print_max = 4L)
```

## Overview  
TODO


|Table 1: Bayesian Optimization (Adapted from @Shahriari2016) |
|:-------------|
|**while** t < N |
|\ \ \ \ evaluate target function $f$ to obtain $y_{t-1}$ |
|\ \ \ \ augment data $\mathbf{X_{0:t}} = \left\{\mathbf{X_{0:t-1}}, \mathbf{x_{t}} \right\}, \ \mathbf{y_{0:t}} = \left\{\mathbf{y_{0:t-1}}, y_{t} \right\}$ |
|\ \ \ \ fit meta model $\mathbf{y_{0:t}} = \mu + Z(\mathbf{X_{0:t-1}})$ |
|\ \ \ \ select new $x_{t}$ by optimizing acquisition function\ \ $LCB =  \hat{y} - \kappa_t\hat{s}$ |
|\ \ \ \ $x_t=\underset{x \in \mathcal{D}}{argmin} \ LCB(x, \mathbf{X_{0:t}}, \mathbf{y_{0:t}})$ |

## Simulation Setup  

First, we will load the package and attach the calibration data that comes with the 
package to the working environment. An installation guide of *r2ogs5* and 
dependencies is given in `vignette("r2ogs5")`. 

```{r, results='hide', message=FALSE}
library(r2ogs5)
set.seed(4242)

options(r2ogs5.default_ogs5_bin = "../inst/ogs/ogs_fem")
```
```{r}
data("groundwater_exp")
groundwater_exp
```
The data contain measurements of hydraulic head in 14 wells located in the Ashi
River basin near the city Acheng in the northeastern province Heilongjiang of
China.

A stationary groundwater model that balances groundwater recharge with
groundwater pumping rates has been set up with OGS for the study area (@Schulz2015)
Here, we will make use of the functionality of **r2ogs5** to add existing input
files into R. The simulation will be carried out in a separate folder
("gw1"), so we can make changes to the input files while keeping the original 
simulation in "groundwater" unchanged.

```{r, results='hide'}
# please specify the correct path to the 'groundwater' folder that can be found
# in r2ogs5/examples in your R-package library. 
input_path <- "../inst/examples/groundwater"

ashi <- create_ogs5(sim_name = "Ashi",
                        sim_id = 1L,
                        sim_path = "gw1")
ashi <- input_add_blocs_from_file(ogs5_obj = ashi,
                                      sim_basename = "Ashi",
                                      filename = "all",
                                      file_dir = input_path)
```

## Design of the target function  

The goal of calibration is to adjust some parameters of the simulation in
`ashi$input`, in order to get a simulation that best represents the experimental
data. As there are many possible forms of experimental data depending on the
design of the experiment, the target function that calculates the difference
between simulation and experiment has to be entirely specified by the user. 
The only requirements for the function are:  

1. One argument called `ogs_obj` that accepts an object of class *ogs5*. For that
argument, the updated *ogs5* object with the simulation results attached in `ashi$output` will be inserted in the target function for every iteration of `?cal_bayesOpt`. 
2. A second argument called `exp_data` for the experimental data. 
3. The output must be a single *numeric* value. 

In this simulation, results for every well are stored in a separate **.tec*-file, that correspond to an entry in `ashi$input$out`. For this specific
case, we will define a function $f$ as our target function.

```{r}
f <- function(ogs5_obj, exp_data) {
   
    ogs5_obj$output <- plyr::ldply(ogs5_obj$output,
                                   function(tbl) {
                                       return(tbl[[1]])
                                   }) %>%
        dplyr::filter(TIME == 1)

    se <- sapply(seq_along(exp_data$well), function(i) {
        ((exp_data$head[i] - ogs5_obj$output$HEAD[i])**2)
    })
    return(mean(se))
}
```

The function `?ogs5_get_output_specific` will load the results for every file as
list elements into `ashi$output`. Therefore, the first step in our function is 
to transform the output section into a single *tibble* by extracting and
stacking the list elements with `ldply`. In the next line, only the last time
point (1) is retained. Now, the `output` matches the experimental data
(`exp_data`), which in this case is stored in `groundwater_exp`. The target 
function is a simple mean squared error, but this is up to the user. 

Of course, it is recommendable to test the function before handing it over to 
the algorithm. Therefore, a single simulation is run  
```{r}
ogs5_write_inputfiles(ashi)
ogs5_run(ashi)
```
and the output is retrieved. In total, output from the whole model domain and 20 wells is returned. This could either be changed by modifying the `ashi$input$out` section prior to running the simulation or by selecting among the output with the function `ogs5_get_output_specific`. Here, the second option is demonstrated and only the output from wells 1 to 10 and 12 to 15 is retrieved according to the available experimental data. 
```{r}
sapply(ashi$input$out, function(x) x$GEO_TYPE)
out_names <- paste0("OUTPUT", c(2:11, 13:16))
out_names
ashi <- ogs5_get_output_specific(ashi, outbloc_names = out_names)
```

Now, the target function can be tested and should yield an value of 122.3887.
```{r}
f(ashi, groundwater_exp)
```
## Initial Sample  

A calibration set as detailed in `?cal_bayesOpt` has to be built, that 
specifies the parameters and their limits that will be calibrated. Therefore,
for each parameter a vector has to be submitted to the function
`cal_create_calibration_set` containing the parameter location as specified in
the *ogs5*-object `ashi`, a character element to place before the parameter value
(here "ISOTROPIC") can be specified if required. Then, lower and upper limits
have to be specified as last elements of each vector.
Documentation on **OGS5** parameters/keys can be looked up here:
https://ogs5-keywords.netlify.app/ogs/wiki/public/doc-auto. 

```{r}
calibration_set <- cal_create_calibration_set(
    c("mmp$MEDIUM_PROPERTIES1$PERMEABILITY_TENSOR", "ISOTROPIC", 1.0e-4, 1.0e-2),
    c("mmp$MEDIUM_PROPERTIES2$PERMEABILITY_TENSOR", "ISOTROPIC", 1.0e-9, 1.0e-4),
    c("mmp$MEDIUM_PROPERTIES3$PERMEABILITY_TENSOR", "ISOTROPIC", 1.0e-7, 1.0e-3),
    c("mmp$MEDIUM_PROPERTIES4$PERMEABILITY_TENSOR", "ISOTROPIC", 1.0e-7, 1.0e-3)
)
```

The calibration set can then be submitted to to the function
`cal_sample_parameters` to get an initial sample of parameters via the Latin 
Hypercube technique, that will be simulated via an ensemble run
(`vignette("Ensembles")`) and evaluated by the target function (`f`) at the start
of the algorithm.

```{r}
init <- cal_sample_parameters(calibration_set,
                              n_samples = 4,
                              interval_01 = FALSE,
                              scale_fun = log10,
                              unscale_fun = function(x) 10**x,
                              )
```
It is recommended to use at least the same number of samples as there are 
parameters in the calibration set, otherwise the Gaussian Process model will have
trouble fitting to fewer observations than features during the first iteration. 

Optionally, a scaling function (`sale_fun`) can be set that will transform the
parameter boundaries before sampling and transform the sampled values back
thereafter via `unsale_fun`. Here, $log_{10}()$ and its inverse $10^x$ are
provided because changes in permeability are usually reported in orders of 
magnitude. This way, the expected amount of samples is equal in intervals of
orders of magnitude, for example between $(1e-4, 1e-3]$ and $(1e-3, 1e-2]$.



## Calibration    

Now, everything is setup to run the Bayesian Optimization algorithm on the 
target function, a summary of the algorithm is given in Table 1.
The initial sample is handed over to `cal_bayesOpt()` as first argument. Next, the
uncertainty weight parameter `kappa` needs to be specified. This can be either a
function depending on dimension `d` of the problem and the current iteration `i`, 
that returns a positive scalar, a constant or one of "cooling" or "log_t" which 
results in different available functions of the package. The respective function
curves are displayed in figure 1. 

```{r, message=T}
bo <- cal_bayesOpt(par_init = init,
                    kappa = "log_t",
                    max_it = 15,
                    exp_data = groundwater_exp,
                    ogs5_obj = ashi,
                    outbloc_names = out_names,
                    ogs_exe = "../inst/ogs/ogs_fem",
                    target_function = f,
                    ensemble_path = "ensembles",
                    ensemble_cores = 2,
                    ensemble_name = "init",
                    scale_fun = log10,
                    unscale_fun = function(x) 10**x)

class(bo)
names(attributes(bo))
```
Further, the experimental data, the *ogs5*-object, the desired output block names,
a path to the **OGS** executable, the target function, a path where to run ensembles,
 a unique name for the ensemble run, the number of cores used for the ensemble,
and the optional scaling functions have to be indicated as function arguments.

The function `cal_bayesOpt` returns an object of class BO that contains the 
Gaussian Proccess meta model (`gp_model`), a vector of all queried parameter points
(`values`),  their resulting target function values (`sim_errors`), the minimum
found (`min`), the prediction and prediction mean squared error
(`pred_mu, pred_sigma`) for all queried points except the initial sample and a 
vector for all `kappa` values used for the acquisition function.

![Figure 1: A) Function for the uncertainty parameter if `kappa = log_t` is chosen. B) Function for different numbers of maximum iterations if `cooling` is chosen.](./figures/kappa.jpg){width=100%}

## Convergence assessment   
The only available stopping criterion until now is the maximum number of iterations,
as a sound generalized stopping criterion, i.e. determining when the global minimum
of the target function is found, is hard to come by. The assessment of convergence 
of the algorithm is therefore deliberately left to the judgment of the user.  

A `plot` method is available to help with the diagnosis of convergence.
It returns 4 figures of the development of different measures (y-axis) through
the iterations/target function calls (x-axis) when applied to an object of class
\emph{BO}. The measures are:  
\enumerate{
\item Current minimum of the target function found by the algorithm.
\item For the current queried point in the parameter space of the simulation model,
the prediction and its respective evaluation by the simulation model or target
function. Also, the confidence region, whose lower bound is used as acquisition
function in the algorithm (\eqn{lcb = ŷ - \kappa ŝ}), is drawn.
\item The so called regret calculated as \eqn{ŷ - y}.
\item The normalized regret \eqn{(ŷ - y) / ŝ}, where ŷ is the prediction by the
meta model, y is the true target function value (both displayed in plot 2)
and ŝ the mean squared error of prediction for the queried point.
}


```{r, fig.width=8, fig.height=6}
r2ogs5:::plot.BO(bo)
```
It is difficult to judge beforehand what an appropriate number of iterations
and thus (expensive) target function calls would be for a specific calibration
problem. 
For convenience, it is possible to continue calibration after an initial run with
a reasonable number of maximum iterations. By simply reintroducing the obtained
*BO*-object in the main function, the algorithm continues from where it stopped
conserving the meta model fitted to the already evaluated points.
All the relevant information is stored in the object either as list elements or 
as attributes, therefore only the arguments as set below have to be provided. 
Further specified Arguments will be overwritten if an initial *BO*-object is
provided, to ensure that e.g. the same target function and experimental data is
used. 

```{r,results='hide', fig.width=8, fig.height=6}
bo2 <- cal_bayesOpt(BO_init = bo, 
             max_it = 30,
             kappa = "log_t",
             ogs_exe = "../inst/ogs/ogs_fem",
             scale_fun = log10,
             unscale_fun = function(x) 10**x)
r2ogs5:::plot.BO(bo2)
```
  
If sufficient convergence is achieved to the criterion of the user, the results
can be used to get a calibrated version of the simulation model. The parameters
that were found to produce a minimum of the target function are stored in 
`bo2$min`, in the format as they are handled inside the algorithm. The 
corresponding minimum value of the target function can be found in `sim_errors`.

```{r}
bo2$min
min(bo2$sim_errors)
```

This has the convenient feature, that a helper function can be used to change the 
parameters inside the simulation object instead of manually changing them.

```{r}
ashi_cal <- cal_change_parameters(ogs5_obj = ashi, par_df = bo2$min)
attributes(ashi_cal)$sim_path <- "ashi_cal"

rbind(calibrated = sapply(ashi_cal$input$mmp, function(x) x$PERMEABILITY_TENSOR),
old = sapply(ashi$input$mmp, function(x) x$PERMEABILITY_TENSOR))
```

The calibrated simulation can now be run one more time and the results displayed.
```{r}
# run simulation and retrieve output
ogs5_write_inputfiles(ashi_cal)
ogs5_run(ashi_cal)
ashi_cal <- ogs5_get_output_specific(ashi_cal, outbloc_names = out_names) 
# squash output into a tibble
ashi_cal$output <- 
  plyr::ldply(ashi_cal$output,
              function(tbl) {
                return(tbl[[1]])
                }) %>%
        dplyr::filter(TIME == 1)
ashi_cal$output$well <- groundwater_exp$well
# plot results 
library(ggplot2)
ggplot(ashi_cal$output, aes(x = well, y = HEAD)) + 
  geom_point() +
  labs(x = "well number", y = "head (m)")

```

Compared to the experimental data, we can see that only comparably small
adjustments to the simulation output can be achieved calibrating permeability 
in this simple model. 

```{r}
ggplot(ashi_cal$output, aes(x = well, y = HEAD, color = "simulation")) + 
  geom_point()+
  geom_point(data = groundwater_exp, aes(y = head, color = "experiment")) +
  labs(x = "well number", y = "head (m)", color = "")

```


## Bibliography



